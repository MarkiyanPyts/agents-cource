{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markiyan Pyts(CV)\n",
      "AI Solutions Architect\n",
      "Contact Information\n",
      "Location: Ukraine, Lviv\n",
      "Email: markiyan.pyts@gmail.com\n",
      "About Me\n",
      "I am a Solutions Architect leading enterprise and product teams in modern AI and cloud initiatives. I love to work with AWS infrastructure as a code, OpenAI APIs, AI Agents, MCP and more.\n",
      "I am also comfortable with Salesforce clouds including Agentforce\n",
      "Top Skills\n",
      "AI Apps Engineering (OpenAI API, OpenAI Agents SDK, MCP, LangChain)\n",
      "AWS Infra As A Code (AWS CDK, Cloud Formation)\n",
      "Node.js\n",
      "Python\n",
      "Serverless & Microservices\n",
      "REST APIs, GraphQL\n",
      "MongoDB(mongoose ODM), Atlas DB, DynamoDB\n",
      "Technical Projects Planning\n",
      "Leadership & Technical Leadership\n",
      "React/Next.js/TanStack\n",
      "Actively Using Claude Code to plan and deliver MVPs and POCs faster then ever before(Spec Driven Agentic AI Powered Development)\n",
      "Other Skills\n",
      "Infrastructure: Docker, AWS ECS, AWS Lambda, AWS SQS, AWS API Gateway, AWS Event Bridge, AWS DynamoDB, AWS Amplify Hosting, AWS Fargate, AWS Step Functions, AWS S3, AWS DLQ (Dead Letter Queue), Cloudflare Pages/Workers, Heroku, GitHub Package Registry\n",
      "Additional BD Skills: Serverless Framework, Beautiful Soup, Rust, Scrapy, Serde, MongoDB transactions, SQL, Yeoman (CLI tools)\n",
      "E-commerce/CRM Platforms: SFCC, SFRA, OCAPI, SCAPI, SLAS, SFCC Page Designer, Salesforce Commerce Cloud, Salesforce Composable Storefront, Salesforce Flows, LWC, AURA, Shopify\n",
      "Frontend Technologies: HTML, CSS, JavaScript, TypeScript, React Router, React Hooks, React Hook Forms, React Native(Expo), Zustand, TailwindCSS, SASS, PWA, Google Lit, Babylon.js, Alpine.js, Vue.js, Vite, Tanstack Router, jQuery\n",
      "Testing & Security: Cypress, Artillery and Playwright(for API load testing) in pair with AWS ECS, OAuth 2.0\n",
      "Performance & Optimization: Performance Optimization, Google Lighthouse\n",
      "Design & User Experience: Figma, UI/UX Design, Data Visualisation, Design front-end architecture and solution blueprints, Mermaid (for architectural diagrams)\n",
      "Pre-sales:  Delivering Project Estimates, Customer Facing Workshops, Presentation Skills\n",
      "Version Control/CI CD: GIT, Github Actions, AWS CodePipeline\n",
      "Marketing/Presentation: Facebook Ads, Final Cut Pro\n",
      "Experience\n",
      "Technical Architect\n",
      "OSF Digital Innovation Team (2025 - Present)\n",
      "Working on shipping and maintaining AI products with OpenAI API, AI Agents and Cloud Infra for them. Very passionate about MCP protocol that makes AI agents so useful these days.\n",
      "Senior FD Solution Architect With Full Stack Focus\n",
      "OSF Digital Innovation Team (2019 - 2025)\n",
      "Worked on Innovation initiatives and projects inside OSF innovation team focusing on Headless technology(Next.js, SF Composable Storefront, AWS Infra) and AI. During this time I also learned a lot about BD tech worked with Nodejs, Python, Rust and more\n",
      "SFCC Front End Solution Architect\n",
      "OSF Digital (2017 - 2019)\n",
      "Mar kiy an Py t s(CV)\n",
      "1Planning FD architecture and leading teams on multiple enterprise e-commerce projects.\n",
      "Front End Developer/Lead\n",
      "OSF Digital (2012 - 2017)\n",
      "Worked as FD dev/technical lead in product and e-commerce projects\n",
      "Flagship Projects In OSF Digital Innovation Team (2019 - 2025) \n",
      "Company: OSF Digital\n",
      "Department: Innovation Team\n",
      "Enterprise AI Assistant Platform\n",
      "Developed an advanced AI chat system similar to ChatGPT, specifically tailored for internal company use with vectored organisational data.\n",
      "Core Features:\n",
      "OpenAI Streaming API integration\n",
      "Next.js frontend with real-time streaming\n",
      "Advanced vector database/data sources for company knowledge\n",
      "Custom prompt system and conversation threading(user being able to talk to multiple specialised AI bots inside single thread conversation)\n",
      "File chunking and vectorisation pipeline\n",
      "Expert bots for specialized topics (e.g., Salesforce Flows)\n",
      "Automatic data source selection based on context\n",
      "Used AWS CDK and SQS queue event driven architecture during Atlas Database Migration to the new data structure of our internal v2 API. To help our BD architect compress many weeks of thread messages migration into under 1 day of time. I made a system that spawned a fleet of thousands parallel AWS lambdas each processing it’s own AI conversation thread as a long running job with retry mechanism based on DLQ. While it worked just fine next time doing something like this I will use Lambda step functions which might make it easier.\n",
      "Future Development: Currently researching MCP (Model Context Protocol) tools integration with OpenAI Agents SDK to enhance capabilities and user experience. I did not own vectorisation part but I am familiar with flow there. In modern Agentic apps vectorisation is slowly being replaced by MCP tools that can serve real time data to the customer accessing it via API but this is still big part of the puzzle so I am looking forward to work with vector databases more.\n",
      "AI-Powered SEO & Content Quality Monitoring System\n",
      "Built an intelligent system for a major e-commerce brand that analyzed web pages and provided SEO optimization recommendations while detecting broken links.\n",
      "Technical Implementation:\n",
      "Python-based scraping engine using Beautiful Soup and Scrapy processing hundreds of pages per brand website\n",
      "Use LangChain Framework\n",
      "AWS CDK infrastructure implementing Fat Lambda(it was big and long living enough to host LangChain at a time) pattern\n",
      "Serverless architecture: AWS Lambda → SQS Queue → Fargate Serverless (Fat Lambda concept) containers for parallel processing\n",
      "Dead Letter Queue for failed scrape tracking\n",
      "API Gateway REST endpoints connected to frontend BFF\n",
      "OpenAI GPT-4 integration with sophisticated retry logic for SEO tag generation\n",
      "Challenges Solved: Overcame GPT-4's character counting limitations through custom control logic\n",
      "Impact: Automated SEO compliance and broken link detection at enterprise scale\n",
      "Legacy Documentation Automation System\n",
      "Collaborated with another architect to create automatic markdown documentation for legacy SFCC and SFDC projects.\n",
      "Technical Approach:\n",
      "Rust-based metadata scraping with serde library and xml parsing lib\n",
      "Parsed SFCC/SFDC metadata files and cartridges\n",
      "OpenAI GPT-4 augmentation for contextual descriptions\n",
      "Used Mermaid to create architectural diagrams in markdown\n",
      "Mar kiy an Py t s(CV)\n",
      "2Automated markdown generation pipeline\n",
      "Result: Comprehensive documentation for legacy systems that would have taken months to create manually or would not be created at all due to the costs and time constrains.\n",
      "OSF Performance Monitor\n",
      "Developed a comprehensive performance monitoring product that continuously tracked e-commerce website performance and accessibility trends for OSF customers.\n",
      "Technical Architecture:\n",
      "Built a Node.js CLI tool published via GitHub Package Registry (chosen for private package hosting without npm costs)\n",
      "Integrated GitHub Actions for automated performance monitoring using Google Lighthouse\n",
      "Implemented Vue.js frontend displaying native Lighthouse HTML reports and custom trend visualisation\n",
      "Designed MongoDB Atlas NoSQL database architecture storing Lighthouse JSON reports\n",
      "Created Node.js REST API with Mongoose ODM supporting MongoDB transactions for data integrity\n",
      "Impact: Enabled proactive performance optimization and accessibility compliance tracking for enterprise e-commerce sites\n",
      "Page Designer Headless(API First) Migration System\n",
      "Architected an API-first migration solution for Salesforce Commerce Cloud's Page Designer CMS, enabling headless applications to leverage existing CMS investments.\n",
      "Key Innovations:\n",
      "Pioneered content preview functionality in legacy Page Designer admin (still unavailable in Salesforce Composable Storefront)\n",
      "Developed sophisticated system exposing SFCC controller-based page structures as REST API endpoints\n",
      "Created Yeoman-based CLI tool automating complex installation processes\n",
      "Implemented three-part architecture: React UI components(powered by system that understood page data structures from BD to build landing pages), SFCC cartridge CMS component models, and Composable Storefront custom REST APIs\n",
      "Business Impact: Saved enterprise clients thousands of dollars monthly by eliminating need for separate CMS subscriptions\n",
      "Additional Contributions: Created comprehensive documentation and mentored development teams on implementation\n",
      "Older SFCC Enterprise Projects (2012 - 2019)\n",
      "Company: OSF Digital\n",
      "Note: Due to NDA agreements, specific client names cannot be disclosed. Projects are referenced by industry and scope.\n",
      "Leading Outdoor Sports & Recreation Multi-Brand Corporation, Front-end Solution Architect\n",
      "Worked with a major American corporation owning multiple outdoor sports and recreation brands. As Front-end Solution Architect I ensured that SFRA architecture is setup correctly to handle multiple brand sites at peak performance possible (over 18 brands were in the pipeline and our multisite reference application needed to support this and allow brand specific customisations). I ensured best practices are followed and helped team to use latest web capability.\n",
      "Key Achievements\n",
      "Developed a new approach with code splitting which allowed reference application to support multiple brand sites without losing performance.\n",
      "Achieved 2x better lighthouse score using SFCC compared to other released SFRA based projects released in same period\n",
      "Platform: Salesforce Commerce Cloud\n",
      "Team Size: 20+\n",
      "Global Cosmetics Brand, Front-end Solution Architect\n",
      "Architected an innovative CMS system based on SFCC content assets that revolutionized content management for a leading cosmetics brand. The system allowed customers to modify content without needing to touch HTML, resembling modern headless CMS systems years before they became mainstream.\n",
      "Key Achievements\n",
      "Designed a component-based architecture that enabled drag-and-drop content management\n",
      "Implemented intuitive interfaces for managing content through text fields and image uploads rather than HTML editing\n",
      "Eliminated the need for technical staff to manage content, empowering marketing teams\n",
      "Mar kiy an Py t s(CV)\n",
      "3Received excellent customer feedback for dramatically simplifying content operations\n",
      "Created a future-proof solution that continues to be used in the enterprise today\n",
      "Platform: Salesforce Commerce Cloud\n",
      "Team Size: 10+\n",
      "Impact: This pioneering approach to content management predated modern headless CMS solutions and demonstrated forward-thinking architecture design\n",
      "Major Gaming Company Headless Migration, Consulting Solution Architect\n",
      "Worked as a consulting SA during a major gaming company's headless SFCC storefront migration from SFRA to custom Headless(API First) Next.js app. My experience from QSR accelerator(more about it in below sections) was useful in defining a secure customer authentication system with SFCC SLAS API.\n",
      "Technology: Salesforce Commerce Cloud SCAPI, SLAS, Next.js, React\n",
      "Team Size: 20+\n",
      "Additional Enterprise Projects: Worked with leading brands in fashion/apparel, cosmetics, telecommunications, gaming, and luxury goods industries\n",
      "Professional Development & Continuous Learning\n",
      "Udemy Certifications\n",
      "I maintain a strong commitment to continuous learning, having completed over 2000 hours of professional development courses. Key certifications include:\n",
      "AI & Machine Learning\n",
      "MCP Crash Course: Complete Model Context Protocol (June 2025) - Certificate\n",
      "LangChain - Develop LLM powered applications (July 2023) - Certificate\n",
      "Cloud & AWS\n",
      "Ultimate AWS Certified Developer Associate 2023 (February 2023) - Certificate\n",
      "Serverless Framework Bootcamp: Node.js, AWS & Microservices (July 2023) - Certificate\n",
      "Build a Secure Data Lake in AWS using AWS Lake Formation (July 2022) - Certificate\n",
      "AWS Serverless Microservices with Patterns & Best Practices (February 2023) - Certificate\n",
      "Frontend & React Development\n",
      "React - The Complete Guide (incl Hooks, React Router, Redux) (November 2020) - Certificate\n",
      "React Native - The Practical Guide [2023] (May 2023) - Certificate\n",
      "Progressive Web Apps (PWA) - The Complete Guide (February 2021) - Certificate\n",
      "3D Programming with WebGL and Babylon.js for Beginners (June 2019) - Certificate\n",
      "E-commerce & Platforms\n",
      "Shopify Theme Development: Online Store 3.0 + TailwindCSS (July 2025) - Certificate\n",
      "Salesforce Certified Platform Developer I (LWC & AURA) (April 2023) - Certificate\n",
      "Testing & Security\n",
      "Cypress: Web Automation Testing from Zero to Hero (July 2024, 10 hours) - Certificate\n",
      "The Nuts and Bolts of OAuth 2.0 (June 2021, 3.5 hours) - Certificate\n",
      "Marketing & Design\n",
      "Facebook Ads & Facebook Marketing Masterclass 2023 (September 2023) - Certificate\n",
      "Learn Figma - UI/UX Design Essential Training (March 2021) - Certificate\n",
      "Salesforce Certifications\n",
      "Salesforce Certified B2C Commerce Developer\n",
      "Salesforce Headless API First Accredited Professional\n",
      "Salesforce Agentforce Specialist\n",
      "Personal Initiatives\n",
      "Mar kiy an Py t s(CV)\n",
      "4B2C COMPONENTS COLLECTION\n",
      "Collection of reusable SFCC Page Designer components useful to launch storefronts faster.\n",
      "Technology: SFCC Page Designer\n",
      "OSF Headless Startup Kit\n",
      "Accelerated transition to headless(API first) commerce by building a RefApp from scratch. Enabled seamless communication with SFCC through OCAPI, creating a decoupled architecture. Utilised modern technology stack to deliver scalable solution.\n",
      "Technology: Salesforce Commerce API, OCAPI \n",
      "OSF Modules System\n",
      "Implemented a custom CMS system powered by SFCC content assets that resembles modern headless CMS UX, it allowed our enterprise customer to manage content without knowing any html(this was more that 7 years ago and was big deal back then). Designed in a block-style format for reusable components, accelerating merchandising and streamlining content management. This system is being used by this Canadian home decor brand even today, so it stood the test of time. Customer was happy and gave great feedback.\n",
      "OmniCommerce\n",
      "OSF Digital stack of products for Composable Storefront.\n",
      "Key Achievements: Introduced Preview Feature for Page Designer headless, that was not available from Salesforce at a time\n",
      "Technology: Salesforce Composable Storefront, SCAPI \n",
      "QSR Accelerator\n",
      "OSF Digital headless solution for quick service restaurants.\n",
      "Developed Fully Custom Headless Reference Application with Next.js and SFCC SCAPI APIs\n",
      "Technology: Next.js / Salesforce Commerce API\n",
      "Recommendations\n",
      "Gerard Szatvanyi\n",
      "Chief AI Officer, Founder, OSF Digital\n",
      "LinkedIn Profile\n",
      "\"I’ve worked closely with Markiyan as he progressed from a junior front-end developer to a trusted technical leader on our team. He’s consistently shown strong technical skills, reliability, and a natural curiosity that drives him to explore and master new technologies. His work has ranged from building user interfaces to designing AI-based systems, always with a practical focus and clear results. Markiyan is thoughtful, dependable, and brings solid value to every project. He would be a great addition to any team looking for a capable and technically curious AI architect.\"\n",
      "Education\n",
      "Master's Degree In Computer Science\n",
      "Lviv Polytechnic National University (2007 - 2012)\n",
      "Went through advanced studies in software engineering, algorithms, AI and systems architecture. Strong foundation in theoretical computer science and practical problem-solving.\n",
      "Languages\n",
      "English(advanced), Ukrainian (native)\n",
      "Articles\n",
      "https://csitjournal.khmnu.edu.ua/index.php/csit/article/download/213/146/733 - THEORETICAL BACKGROUND FOR CREATING REAL WORLD DATA LAKE ARCHITECTURE ON AWS\n",
      "Mar kiy an Py t s(CV)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Markiyan Pyts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
